#!/usr/bin/env python3

import argparse
import scipy.stats as sts
import numpy as np
import sys
import process_bam as pb
import ploidy_model as pm
import plot_read_data as plot
import nbinom as nb


def save_tsv(aicllh, pld, out, incl):
    if incl:
        out.write("Ploidy\tLog_Likelihood\tAIC\tHet_Weights\tUniform_Weight\tBinomial_Err_Weight\n")
    else:
        out.write("Ploidy\tLog_Likelihood\tAIC\tHet_Weights\tUniform_Weight\n")
    for i in range(len(pld)):
        w = str(aicllh[2][i])[1:-1].split()
        if incl:
            out.write("%s\t%s\t%s\t%s\t%s\t%s\n" % (pld[i], aicllh[0][i], aicllh[1][i], ",".join(w[:-2]), w[-1], w[-2]))
        else:
            out.write("%s\t%s\t%s\t%s\t%s\n" % (pld[i], aicllh[0][i], aicllh[1][i], ",".join(w[:-1]), w[-1]))


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers(dest='subparser')

    process_bam = subparsers.add_parser("process_bam")
    process_bam.add_argument("--bam", required = True)
    process_bam.add_argument("--out", required = True)
    process_bam.add_argument("--bed", default = False)
    process_bam.add_argument("--quality", default = 15, type = int)

    denoise = subparsers.add_parser("filter")
    denoise.add_argument("--count_file", required = True)
    denoise.add_argument("--out", required = True)
    denoise.add_argument("--error_prob", type = float, required = True)

    histo = subparsers.add_parser("histo")
    histo.add_argument("--count_file", required = True)
    histo.add_argument("--out", required = True)

    assess = subparsers.add_parser("assess")
    assess.add_argument("--count_file", required = True)
    assess.add_argument("--min_cov",type = int, default = 1)
    assess.add_argument("--max_cov", type = int, default = 0)
    assess.add_argument("--ploidies", nargs='+', type = int, required = True)
    assess.add_argument("--error_prob", type = float, default = 0)
    assess.add_argument("--out", default = None)


    args = parser.parse_args()

    if args.subparser == 'process_bam':
        print("Now processing BAM file %s..." % args.bam)
        if args.bed:
            print("\tprocessing subset found in %s" % args.bed)
        pb.get_biallelic_coverage(args.bam, args.out, args.bed, args.quality)
        print("Success!")
    elif args.subparser == 'filter':
        print("Filtering count file %s..." % args.count_file)
        np.savetxt(args.out, pb.denoise_reads(args.count_file, args.error_prob)[1],
                   fmt='%d')
        print("Filtered data sucessfully saved in %s" % args.out)
    elif args.subparser == 'histo':
        cnts = np.loadtxt(args.count_file)
        plot.plot_joint_dist(cnts, args.out + ".pdf")
        print("Files saved in %s.pdf!" % args.out)
    elif args.subparser == 'assess':
        cnts = np.loadtxt(args.count_file)
        #max_v = np.percentile(cnts[:,1], 95) if args.max_cov == 0 else args.max_cov
        #cnts = cnts[np.logical_and(cnts[:,1] >= args.min_cov, cnts[:,1] <= max_v)]
        r, p_nb = nb.fit_nbinom(cnts[:,1])
        pld = np.array(args.ploidies)
        aicllh = pm.get_Log_Likelihood_AIC(cnts, pld, r, p_nb, args.error_prob)
        if args.out:
            f = open(args.out, "w+")
            save_tsv(aicllh, pld, f, not args.error_prob == 0)
            f.close()
        else:
            save_tsv(aicllh, pld, sys.stdout, not args.error_prob == 0)
        print("The most likely model is %s-ploid." % pm.select_model(aicllh[1], pld))
